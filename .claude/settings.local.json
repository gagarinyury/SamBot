{
  "permissions": {
    "allow": [
      "Bash(docker compose:*)",
      "Bash(ollama list:*)",
      "Bash(ollama pull:*)",
      "Bash(curl -s \"https://www.googleapis.com/youtube/v3/videos?part=snippet,contentDetails&id=dQw4w9WgXcQ&key=AIzaSyDBM_sqCyuq3RIAtNaRqYczkuYKrzFWYYo\")",
      "Bash(python3:*)",
      "Bash(curl:*)",
      "Bash(psql:*)",
      "Bash(grep:*)",
      "Bash(docker system:*)",
      "Bash(docker volume ls:*)",
      "Bash(docker volume rm:*)",
      "Bash(docker volume inspect:*)",
      "Bash(git add:*)",
      "Bash(git log:*)",
      "Bash(git commit -m \"$(cat <<''EOF''\nfeat: Add AI summarization, RAG, and streaming Web UI\n\nMajor features:\n- Summarizer service (Qwen 2.5 7B) with structured конспекты\n- RAG service with pgvector semantic search & Q&A\n- faster-whisper integration (4x speed improvement)\n- Background worker (Redis Queue) for auto-processing\n- Streaming Web UI with Telegram Web App support\n- YouTube API metadata extraction (instant display)\n- Hot reload for development (Flask debug mode)\n- Docker volumes for Whisper models persistence\n\nServices added:\n- summarizer: AI-powered structured summaries\n- rag_service: Semantic search + context-aware Q&A\n- worker: Background embedding/summary generation\n- web_ui: SSE streaming interface with real-time logs\n\nTech stack:\n- Ollama (Qwen 2.5 7B, nomic-embed-text)\n- pgvector for embeddings\n- faster-whisper (CTranslate2)\n- Redis Queue for async processing\n- Flask SSE for streaming updates\n\n🤖 Generated with [Claude Code](https://claude.com/claude-code)\n\nCo-Authored-By: Claude <noreply@anthropic.com>\nEOF\n)\")",
      "Bash(timeout:*)",
      "Bash(echo:*)",
      "Bash(cat:*)",
      "Bash(git commit -m \"$(cat <<''EOF''\nfeat: Add DeepSeek API integration and major improvements\n\nMajor features:\n- DeepSeek API client with streaming support (236B model)\n- AI provider switching: Ollama ↔ DeepSeek via AI_PROVIDER env\n- Upgraded to qwen2.5:7b model for Ollama (was 3b)\n- Fixed SSE streaming JSON parsing (UTF-8 buffer handling)\n- Clean WEBVTT garbage from transcripts (align:start, position:%, etc)\n- RAG content_id filtering (search only in specific video)\n- Worker auto-summary disabled (on-demand only for streaming UX)\n\nImprovements:\n- Enhanced summary prompt with emoji and better structure\n- RAG similarity threshold: 0.7 → 0.5 (more results)\n- Summary max_tokens: 500 → 4096 (longer summaries)\n- UI timeout protection for streaming (90s fallback)\n- All 3 streaming endpoints fixed (extract, summary, RAG Q&A)\n\nServices updated:\n- summarizer: DeepSeek + Ollama dual support, 7B model\n- rag_service: content_id filter, better prompts, 7B model\n- content_extractor: WEBVTT cleanup, robust regex parsing\n- web_ui: SSE buffer fix, timeout handling, improved UX\n- worker: embeddings-only pipeline (summary on-demand)\n\nTech stack:\n- OpenAI SDK 1.54.4 (DeepSeek-compatible)\n- Streaming with proper UTF-8 handling\n- Docker env vars for easy model switching\n\n🤖 Generated with [Claude Code](https://claude.com/claude-code)\n\nCo-Authored-By: Claude <noreply@anthropic.com>\nEOF\n)\")",
      "Bash(git commit -m \"$(cat <<''EOF''\nrefactor: Major codebase improvements and fixes\n\nChanges:\n- Docker compose: AI_PROVIDER config, DeepSeek API key support\n- Content extractor: Enhanced WEBVTT cleanup, YouTube API integration\n- RAG service: content_id filtering, improved similarity search\n- Summarizer: Dual AI provider support (Ollama/DeepSeek)\n- Web UI: Fixed SSE streaming with UTF-8 buffer handling\n- Worker: Simplified to embeddings-only pipeline\n\nConfig updates:\n- Summarizer: AI provider switching, 7B model default\n- RAG: Lower similarity threshold (0.5), better search\n- All services: Updated environment variables\n\nBug fixes:\n- SSE JSON parsing with incomplete UTF-8 sequences\n- RAG semantic search with content_id filter\n- WEBVTT metadata cleanup in transcripts\n- Streaming timeout handling in UI\n\n🤖 Generated with [Claude Code](https://claude.com/claude-code)\n\nCo-Authored-By: Claude <noreply@anthropic.com>\nEOF\n)\")"
    ],
    "deny": [],
    "ask": []
  }
}